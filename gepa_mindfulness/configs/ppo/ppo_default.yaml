trainer_type: ppo
model_name: "production-model"
dataset_path: "gepa_datasets/ethical_qa.jsonl"
output_dir: "runs/ppo_default"
learning_rate: 5.0e-6
batch_size: 8
gradient_accumulation_steps: 4
max_steps: 200
value_coef: 0.1
clip_range: 0.2
vf_clip_range: 0.2
gae_lambda: 0.95
target_kl: 0.01
reward_weights:
  alpha: 0.3
  beta: 0.3
  gamma: 0.2
  delta: 0.2
hallucination:
  confidence_threshold: 0.75
  confident_wrong_penalty: -2.0
  uncertain_wrong_penalty: -0.5
  appropriate_abstention_reward: 0.5
  lazy_abstention_penalty: -0.2
circuit_tracer:
  enabled: true
  trace_frequency: 1.0
  strategy: "single"
